library(tidyr);
library(dplyr);
library(kableExtra);
library(ggplot2)
data<- read.csv("https://raw.githubusercontent.com/deepasharma06/Data621-HW2/main/classification-output-data.csv")
head(data) %>% kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = TRUE, position = "center", font_size = 15)
#row: predicted value; columns: actual value
conf_matrix = table(Prediction = data$scored.class, Actual = data$class)
conf_matrix %>% kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = TRUE, position = "center", font_size = 15)
accuracy = function(data, predicted_col_name, actual_col_name) {
conf = table(data[ , predicted_col_name], data[ , actual_col_name])
TP = conf[2,2]
TN = conf[1,1]
FP = conf[2,1]
FN = conf[1,2]
#Accurary = (TP + TN) / (TP + FP +TN +FN)
return(round((TP+TN)/(TP + FP + TN + FN), 4))
}
errorRate = function(data, predicted_col_name, actual_col_name) {
conf = table(data[ , predicted_col_name], data[ , actual_col_name])
TP = conf[2,2]
TN = conf[1,1]
FP = conf[2,1]
FN = conf[1,2]
#Classification Error Rate = ( FP + FN )/(TP + FP +TN +FN)
return(round((FP+FN)/(TP + FP + TN + FN), 4))
}
print(paste0("Error rate: ", errorRate(data, 'scored.class', 'class')))
#accuracy + error rate
print(paste0("Accuracy + Error rate = ", accuracy(data, 'scored.class', 'class'), " + ", errorRate(data, 'scored.class', 'class'), " = ", (accuracy(data, 'scored.class', 'class') + errorRate(data, 'scored.class', 'class'))))
precision = function(data, predicted_col_name, actual_col_name) {
conf = table(data[ , predicted_col_name], data[ , actual_col_name])
TP = conf[2,2]
TN = conf[1,1]
FP = conf[2,1]
FN = conf[1,2]
#Precision = TP / (TP + FP)
return(round((TP)/(TP + FP), 4))
}
print(paste0("Precision: ", precision(data, 'scored.class', 'class')))
sensitivity = function(data, predicted_col_name, actual_col_name) {
conf = table(data[ , predicted_col_name], data[ , actual_col_name])
TP = conf[2,2]
TN = conf[1,1]
FP = conf[2,1]
FN = conf[1,2]
#Sensitivity = TP / (TP + FN)
return(round((TP)/(TP + FN), 4))
}
print(paste0("Sensitivity: ", sensitivity(data, 'scored.class', 'class')))
specificity = function(data, predicted_col_name, actual_col_name) {
conf = table(data[ , predicted_col_name], data[ , actual_col_name])
TP = conf[2,2]
TN = conf[1,1]
FP = conf[2,1]
FN = conf[1,2]
#Specificity = TN / (TN+FP)
return(round((TN)/(TN + FP), 4))
}
print(paste0("Specificity: ", specificity(data, 'scored.class', 'class')))
f1_score = function(data, predicted_col_name, actual_col_name) {
p = precision(data, 'scored.class', 'class')
s = sensitivity(data, 'scored.class', 'class')
return(2*p*s/(p+s))
}
print(paste0("F1 Score: ", f1_score(data, 'scored.class', 'class')))
getROCcurve = function(col.true = "class", col.probability = "scored.probability", data) {
vec.TPR = c()
vec.TNR = c()
for (i in seq(0, 1, 0.01)) {
data = data %>% mutate(model.classification = ifelse(unlist(select(data, col.probability)) < i, 0, 1))
i.vec.TP = data %>% filter(model.classification == class & class == 1) %>% nrow()
i.vec.FN = data %>% filter(model.classification != class & class == 1) %>% nrow()
i.vec.TN = data %>% filter(model.classification == class & class == 0) %>% nrow()
i.vec.FP = data %>% filter(model.classification != class & class == 0) %>% nrow()
vec.TPR = c(vec.TPR, (i.vec.TP/(i.vec.TP + i.vec.FN)))
vec.TNR = c(vec.TNR, (i.vec.TN/(i.vec.TN + i.vec.FP)))
}
df.ROC = data.frame(Threshold = seq(0, 1, 0.01), TNR = vec.TNR, TPR = vec.TPR)
df.ROC = df.ROC %>% arrange(TNR, decreasing = T)
plt.ROC = ggplot(aes(x = 1-(TNR), y = (TPR)), data = df.ROC) + geom_step() + labs(x = "1 - Specificity", y = "Sensitivity")
df.AUC  = df.ROC %>% distinct(TPR, TNR)
df.AUC <- df.AUC %>%  mutate(TNR_next = lead(TNR, n = 1L))
df.AUC$width = df.AUC$TNR_next - df.AUC$TNR
vec.AUC = sum(df.AUC$width * df.AUC$TPR, na.rm = T)
return(list("AUC" = vec.AUC, "ROC" = plt.ROC))
}
print(paste0("Accuracy: ", accuracy(data, 'scored.class', 'class')))
print(paste0("Error rate: ", errorRate(data, 'scored.class', 'class')))
print(paste0("Precision: ", precision(data, 'scored.class', 'class')))
print(paste0("Sensitivity: ", sensitivity(data, 'scored.class', 'class')))
print(paste0("Specificity: ", specificity(data, 'scored.class', 'class')))
print(paste0("F1 Score: ", f1_score(data, 'scored.class', 'class')))
getROCcurve(data = data)
